{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ce57ba",
   "metadata": {},
   "source": [
    "# Block I: Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a9c52d",
   "metadata": {},
   "source": [
    "1. What is sound:\n",
    "    Sound is a presseure change in pressure in air\n",
    "    - sound = rapid changes of air pressure\n",
    "    - sound travels through space as a pressure wave \n",
    "    - sound is a longitudinal wave\n",
    "    \n",
    "<img src=\"./block_1/sound.gif\">\n",
    "\n",
    "\n",
    "2. What is a pure tone? Why is it referred to as a sinusoid:\n",
    "\n",
    "    A pure tone is a sound wave characterized by a single frequency, meaning it consists of only one frequency component without any harmonics or overtones. It is referred to as a sinusoid because the waveform of a pure toneis mathematically described by a sine wave, which is a fundamental trigonometric function representing simple harmonic motion.\n",
    "    \n",
    "    \n",
    "3. What is a waveform:\n",
    "\n",
    "    A weveform it the representation(shape, pattern) of the sound in time domain\n",
    "   \n",
    "<img width=\"300px\" src=\"./block_1/waveform.gif\">    \n",
    "\n",
    "4. What is frequency, amplitude and phase of a pure tone:\n",
    "    - FREQUENCY: The number of cycles per second (Hz).\n",
    "    - AMPLITUDE: The magnitude of the sinewave (e.g. Pascal).\n",
    "    - PHASE: The point at which the sinusoid starts (in deg or rad)\n",
    "    \n",
    "<img width=\"300px\" src=\"./block_1/sinwave.png\">\n",
    "\n",
    "\n",
    "5. What is a complex signal:\n",
    "    \n",
    "    A complex signal is a combination of multiple pure tones.\n",
    "    Since the wave does not have the ‘simple’ form of the sinewave anymore it is called a complex wave\n",
    "    \n",
    "    \n",
    "6. Why is frequency, amplitude and phase particularly meaningful for pure tones and not for complex signals:\n",
    "\n",
    "    Frequency, amplitude, and phase are particularly meaningful for pure tones because a pure tone is a single-frequency waveform where these parameters directly define its pitch (frequency), loudness (amplitude), and starting point of the waveform (phase). In contrast, complex signals contain multiple frequencies and phase relationships, making these parameters more complex to interpret and analyze.\n",
    "    \n",
    "7. What is a spectrum:\n",
    "\n",
    "    A spectrum refers to a representation of a signal or wave in terms of its frequency components. It shows how the energy or amplitude of the signal is distributed across different frequencies. A spectrum can be obtained by performing Fourier transform on the signal, which decomposes it into its constituent frequency components. The spectrum provides valuable information about the frequency content of the signal, including dominant frequencies, harmonics, and overall frequency characteristics\n",
    "    \n",
    "<img width=\"300px\" src=\"./block_1/waveform.gif\"><img width=\"300px\" src=\"./block_1/spectrum.gif\">  \n",
    "\n",
    "8. What does the spectrum of a complex signal never look like:\n",
    " \n",
    "    It will have never have only one peak, since it conists of multiple sinusoids with different frequencies, therefore it will have multiple peaks\n",
    "\n",
    "\n",
    "9. What does the waveform of a complex signal never look like:\n",
    "\n",
    "    The waveform of a complex signal never looks like a simple, regular sinusoidal wave or a straightforward repetitive pattern. \n",
    "    \n",
    "10. How do you calculate frequency from a given period duration:\n",
    "    \n",
    "    $T$ is the perdion and and $f$ the frequncy\n",
    "    $$ f = {1 \\over T} $$\n",
    "\n",
    "11. How do you calculate period duration from a given frequency:\n",
    "\n",
    "    $$ T = {1 \\over f} $$\n",
    "    \n",
    "12. What is the difference between sec and ms:\n",
    "\n",
    "    $$ 1s = 1000ms $$\n",
    "    \n",
    "13. Name different ways for measuring amplitude and their pros and cons:\n",
    "    - peak measure\n",
    "    <img width=\"600px\" src=\"./block_1/peakmeasure.jpg\">\n",
    "        - pros\n",
    "            - Simple and straightforward method\n",
    "            - Provides a clear indication of the signal's maximum amplitude.\n",
    "        - cons\n",
    "            - Does not account for the distribution of energy across the signal.\n",
    "            - May not represent the overall \"strength\" or energy content of the signal accurately, especially for complex singal.\n",
    "    - root-mean-square $$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_i)^2} $$ $x_i$ are the measure points of the signal\n",
    "        <img width=\"600px\" src=\"./block_1/root_mean_measure.jpg\">\n",
    "        - pros\n",
    "            - Provides a measure of the effective \"strength\" or power of the signal by considering the entire amplitude distribution.\n",
    "            - Reflects the heating or power dissipation characteristics of the signal (relevant in electrical applications).\n",
    "        - cons\n",
    "            - More computationally intensive compared to peak measurement.\n",
    "            - Can be influenced by transient spikes or noise in the signal, although it generally provides a more representative measure of amplitude compared to peak value alone.\n",
    "\n",
    "\n",
    "14. What is the difference between a linear scale like Pa, mm or V and the Decibel scale:\n",
    "    \n",
    "    Decible scale uses as logarithmic scale and and a refrence Pressure.\n",
    "    Decibels represent relative differences or ratios rather than absolute values. They quantify the logarithmic relationship between two quantities\n",
    "    \n",
    "15. What are the three main ideas underlying the decibel scale?\n",
    "    \n",
    "    - Point of reference \n",
    "        - refer to threshold of hearing (0 dBSPL)\n",
    "    - Rescale Data\n",
    "        - e.g. 20 – 100 000 µPa more detailed\n",
    "        - e.g. 1 000 000 – 200 000 000 µPa less detailed \n",
    "        - This type of scaling (logarithmic scaling) also is much closer to human hearing. \n",
    "\n",
    "    - Handling big numbers\n",
    "        - 20 - 200 000 000 µPa  equals 0 – 140 dB\n",
    "    \n",
    "16. What does dBSPL stand for and what does it imply:\n",
    "    \n",
    "    The term \"dBSPL\" stands for decibels Sound Pressure Level\n",
    "    It refers to the threshold of hearing (0 dbSPL).\n",
    "    Reference Level (SPL0): The reference pressure level used in dBSPL is typically 20 micropascals (μPa), which is considered the threshold of human hearing at a frequency of 1 kHz. Therefore, dBSPL measures the sound pressure level relative to this reference level.\n",
    "\n",
    "17. What do positive and negative numbers of the dBSPL scale imply: \n",
    "    - 0 dB does not mean no sound; it means the same as the reference\n",
    "    - Any positive number of dB means greater than the reference (e.g., 10 dB)\n",
    "    - Any negative number of dB means less than the reference (e.g., -10 dB)\n",
    "    \n",
    "18. What is a sound of 50 micro Pascals expressed in dBSPL:\n",
    "\n",
    "    $$ \\text{SPL}_{\\text{dBSPL}} = 20 \\times \\log_{10} \\left( \\frac{P_{\\text{rms}}}{P_{\\text{ref}}} \\right) $$\n",
    "    \n",
    "    50 micro Pascal in dbSPL:\n",
    "    $$ 20 \\times \\log_{10} \\left( \\frac{50}{20} \\right) = 7.958dBSPL $$\n",
    "\n",
    "19. What is 28 dBSPL in micro Pascals:\n",
    "    $$ a^x = b $$\n",
    "    $$ log_a(a^x) = \\log_a(b) $$\n",
    "    $$ x = \\log_a(b) $$\n",
    "    $$ 28 = 20 \\times \\log_{10} \\left( \\frac{P}{20} \\right) $$\n",
    "    $$ \\frac{28}{20} = \\log_{10} \\left( \\frac{P}{20} \\right) $$\n",
    "    $$ 10^{(\\frac{28}{20})} =  \\frac{P}{20} $$\n",
    "    $$ 10^{(\\frac{28}{20})} \\times 20 =  P $$\n",
    "    $$ P = 20 \\times 10^{1.4} = 20 \\times 25.1189 = 502.378μPa $$\n",
    "\n",
    "\n",
    "20. What is the relationship between pascals and micro pascals:\n",
    "\n",
    "    $$ 1 \\text{ Pascal (Pa)} = 10^6 \\text{ micro Pascals (μPa)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257eab75",
   "metadata": {},
   "source": [
    "# Block 2: Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb21eec0",
   "metadata": {},
   "source": [
    "1. What is meant by the term \"acoustic system\" and what are some examples of acoustic systems?\n",
    "\n",
    "    An acoustic system is something that changes the characteristics of an acoustic signal\n",
    "        - Microphones and Speakers\n",
    "        - Headphones\n",
    "        - Sound Reinforcement Systems\n",
    "     Characteristic of accoustic system: Frequency, amplitude, phase, the change between input and output\n",
    "\n",
    "2. In what ways can a linear time-invariant (LTI) system modify the characteristics of a signal, such as its amplitude, frequency content, or phase? \n",
    "    \n",
    "    They do not change the frequency but they can change phase and amplitude\n",
    "    \n",
    "3. What is meant by the terms \"additivity\", \"homogeneity\" and time-invariance in the  context of an LTI system, and how does it relate to the system's behavior?\n",
    "    -  additivity: An LTI system is additive if the response to the sum of two input signals is equal to the sum of the responses to each individual input sign.\n",
    "    $$ T\\{x_1(t) + x_2(t)\\} = T\\{x_1(t)\\} + T\\{x_2(t)\\} $$\n",
    "    here $ T\\{ \\} $ denotes the linear system and $ x_1(t) $ and $ x_2(t) $ are the input signals\n",
    "    \n",
    "    - homogeneity: n LTI system is homogeneous if scaling the input signal by a constant results in scaling the output signal by the same constant.\n",
    "        $$ T\\{a \\cdot x(t)\\} = a \\cdot T\\{x(t)\\} $$\n",
    "    - time-invariance: Time-invariance means that an LTI system's response remains unchanged over time, regardless of when the input signal is applied:\n",
    "    $$ T\\{x(t - \\tau)\\} = y(t - \\tau) $$\n",
    "    where  $  y(t) = T\\{x(t)\\} $ and  $  \\tau  $ is a time shift.\n",
    "<img width=\"400px\" src=\"./block_2/linearsystem.jpg\">\n",
    "\n",
    "    to be linaer the line must puss through the origin\n",
    "\n",
    "4. How does an LTI system affect the amplitude of a signal passing through it, and what factors can influence this effect?\n",
    "    An LTI system can scale the amplitude of a signal passing through it. This scaling factor is determined by the system's impulse response or transfer function.\n",
    "    If the system amplifies the signal, it increases the amplitude, while if it attenuates the signal, it decreases the amplitude. The amount of scaling depends on the characteristics of the system, such as its gain or attenuation properties.\n",
    "    \n",
    "    Filtering Effects:\n",
    "    In the frequency domain, LTI systems act as filters that can selectively amplify or attenuate specific frequency components of a signal.\n",
    "    Depending on the system's frequency response, certain frequencies may be amplified (passband) or attenuated (stopband).\n",
    "    This frequency-dependent behavior can lead to variations in amplitude across different frequency components of the signal.\n",
    "\n",
    "5. Does an LTI system maintain its properties over time, or can they change due to external factors or internal dynamics?\n",
    "    A perfect LTI  to internal dynamics they should not change, but the compone can age\n",
    "    But it is possible that they change due to external effects\n",
    "    \n",
    "6. How can an LTI system be characterized or represented mathematically:\n",
    "\n",
    "    already shown in 3)\n",
    "\n",
    "7. What is the frequency response of an LTI system:\n",
    "\n",
    "    Response = Output amplitude/Input amplitude\n",
    "\n",
    "    So on linear scales\n",
    "        - Output amplitude = Response x Input amplitude\n",
    "        - Overall amplitude response is product of component responses (e.g., multiply the amplitude responses) \n",
    "\n",
    "    \n",
    "    But on dB (logarithmic) scales\n",
    "        - Output amplitude = Response + Input amplitude\n",
    "        - Overall amplitude response is the sum of the component responses (i.e., sum the amplitude responses) …\n",
    "        - Because taking logarithms turns multiplication into addition: log(a x b) = log(a) + log(b)\n",
    "<img width=\"400px\" src=\"./block_2/response.jpg\">\n",
    "    \n",
    "7. What is the transfer function of an LTI system:\n",
    "    also known as the frequence repsonse, see picture above\n",
    "    \n",
    "8. What is a non-linear system:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980ca97",
   "metadata": {},
   "source": [
    "# Block 3: Signals & Systems in Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9728b",
   "metadata": {},
   "source": [
    "<img width=\"400px\" src=\"./block_3/formants.jpg\">\n",
    "1. Explain the fundamental idea of the source-filter model:\n",
    "    The source-filter model of speech production describes how speech sounds are created. It proposes two main components:\n",
    "\n",
    "    - Source: The vibrating vocal cords produce a raw sound source.\n",
    "    - Filter: The vocal tract modifies this sound through resonance, shaping it into distinct speech sounds.\n",
    "    \n",
    "    By changing the configuration of the vocal tract (like tongue position or lip shape), different sounds are produced. This model helps explain how we create specific speech sounds and study their acoustic properties.\n",
    "\n",
    "\n",
    "2. What is meant by source and filter being independent? What can you do with the source, what with the filter:\n",
    "    In the source-filter model, the independence of the source and filter means they can be adjusted separately:\n",
    "\n",
    "    - Source: Manipulating the source involves changing properties like pitch and intensity by altering vocal cord vibration.\n",
    "    - Filter: Manipulating the filter involves changing vocal tract shape (tongue, lips, jaw) to modify resonance and produce different speech sounds.\n",
    "    \n",
    "    Understanding their independence helps study speech production and develop technologies like speech synthesis with greater control over speech characteristics.\n",
    "\n",
    "\n",
    "3. How does the back cavity of the vocal tract and the front cavity relate to the highest point of the tongue:\n",
    "    By adjusting the position of the highest point of the tongue along with the configuration of the vocal tract's back and front cavities, different vowel sounds are produced. This relationship demonstrates how articulatory adjustments in the tongue and vocal tract contribute to the distinct qualities of vowels in spoken language.\n",
    "    \n",
    "    \n",
    "4. How do the back and front cavities of the vocal tract play together to produce vowels in a two-tube model:\n",
    "    <img width=\"400px\" src=\"./block_3/cavities.jpg\">\n",
    "    In the two-tube model, the vocal tract is represented by two interconnected tubes: a longer tube representing the pharyngeal cavity (back cavity) and a shorter tube representing the oral cavity (front cavity).\n",
    "    These tubes are considered to be resonators that can independently amplify certain frequencies of the sound produced by the vocal cords (the source).\n",
    "    \n",
    "    The length of each tube (front and back cavity) can be adjusted by changing the configuration of the vocal tract, primarily through movements of the tongue, lips, and jaw.\n",
    "    Shortening or lengthening these tubes alters their resonant frequencies, which in turn affects the acoustic properties of the sound passing through them.\n",
    "    \n",
    "    Role of Back Cavity:\n",
    "    The back cavity (pharyngeal cavity) influences the resonance of low-frequency components of the sound. By changing the size and shape of the back cavity (e.g., by lowering or raising the soft palate), different resonant frequencies are emphasized or attenuated.\n",
    "    In back vowels (like [ɑ] or [u]), the back cavity is relatively larger and more open, favoring resonance of lower frequencies.\n",
    "    \n",
    "    Role of Front Cavity: The front cavity (oral cavity) affects the resonance of higher-frequency components of the sound. Altering the shape and size of the oral cavity (e.g., by varying tongue height and advancement) changes the resonant frequencies amplified by this cavity.\n",
    "    In front vowels (like [i] or [e]), the oral cavity is relatively smaller and more constricted, favoring resonance of higher frequencies.\n",
    "5. What is a three-tube model of the vocal tract:\n",
    "\n",
    "\n",
    "    The three-tube model of the vocal tract is a theoretical framework used to describe vowel production based on the acoustic properties of three interconnected resonating tubes that represent different regions of the vocal tract. This model builds upon the concept of the two-tube model by further dividing the vocal tract into additional segments to better capture the complexity of vowel articulation and resonance.\n",
    "       \n",
    "<img width=\"400px\" src=\"./block_3/three_tube_model.jpg\">\n",
    "    \n",
    "6. Which properties of the three-tube model explain f1? Which ones f2? And which ones f3:\n",
    "    - F1: Influenced by the length of the pharyngeal tube (back cavity). Longer tube length corresponds to lower F1 frequencies.\n",
    "    - F2: Influenced by the length and configuration of the oral tube (middle cavity). Longer tube length corresponds to lower F2 frequencies.\n",
    "    - F3: Influenced by the length and configuration of the labial tube (front cavity). Longer tube length corresponds to lower F3 frequencies.\n",
    "\n",
    "7. Which vowels are the corner vowels and what does that mean:\n",
    "\n",
    "    Corner vowels are important because they represent extreme positions within the vowel space, serving as anchor points for describing and comparing other vowels based on their articulatory characteristics and acoustic properties. They provide a standardized framework for analyzing and classifying vowels in different languages and speech varieties.\n",
    "    \n",
    "    [i] (close front unrounded vowel): This is a high front vowel where the tongue is raised close to the roof of the mouth and positioned towards the front. It is a reference point for high front vowels.\n",
    "    \n",
    "    [u] (close back rounded vowel): This is a high back vowel where the tongue is raised close to the roof of the mouth and positioned towards the back, with rounded lips. It serves as a reference point for high back vowels.\n",
    "    \n",
    "    [a] (open central unrounded vowel): This is a low central vowel where the tongue is lowered and positioned in the middle of the mouth. It is a reference point for low central vowels.\n",
    "    \n",
    "    [ɑ] (open back unrounded vowel): This is a low back vowel where the tongue is lowered and positioned towards the back of the mouth. It is used as a reference point for low back vowels.\n",
    "\n",
    "8. What do we find when we take lots of formant samples of the same vowles of many speakers:\n",
    "\n",
    "    Practically it is messy\n",
    "    \n",
    "<img width=\"400px\" src=\"./block_3/practically.jpg\">\n",
    "\n",
    "9. What are the main sub-systems of the human ear and what signal processing procedures happen in each of these components:\n",
    "    <img width=\"400px\" src=\"./block_3/ear.jpg\">\n",
    "    \n",
    "    - outer ear:\n",
    "    \n",
    "        - Funnel shaped pinna “collects” sounds from environment\n",
    "        - Pinna and ear canal affect the frequency content of sounds filtering\n",
    "        - Having two ears (instead of one) is important for sound localisation\n",
    "            differences between what each ear ‘hears’ \n",
    "    - middle ear:\n",
    "        - Main parts: tympanic membrane, malleus, incus, stapes\n",
    "        - Provides coupling from eardrum to cochlea.\n",
    "        - Impedance matching (he process by which the middle ear efficiently transfers sound waves from the outer ear (air-filled) to the inner ear (fluid-filled).) through ~20:1 area ratio, and lever ratio of ~1.3.\n",
    "        - Lever ratio varies with frequency: peaks at 2 kHz with ~5.\n",
    "        - Stapedius reflex provides protection of cochlea from intense sounds\n",
    "    - inner ear:\n",
    "        - Cochlear Transduction: Sound vibrations entering the cochlea cause fluid within it to move, stimulating hair cells (mechanoreceptors) that convert mechanical energy into electrical signals.\n",
    "        - Frequency Analysis: Different frequencies of sound stimulate different regions along the length of the cochlea, resulting in a tonotopic map where higher frequencies are detected at the base and lower frequencies at the apex.\n",
    "        - Neural Coding: Electrical signals generated by hair cells are transmitted through the auditory nerve to the brainstem and then to the auditory cortex, where they are processed into meaningful sound perception.\n",
    "\n",
    "             \n",
    "             \n",
    "10. Subdivide the outer and middle ear into plausible sub-systems:\n",
    "    - outer ear:\n",
    "        - Pinna (Auricle):\n",
    "            - Function: Collects and directs sound waves into the ear canal.\n",
    "            - Frequency Response: The pinna enhances sound frequencies in the range of 2-5 kHz, which is important for localizing the direction of sound sources.\n",
    "        - Ear Canal (External Auditory Canal):\n",
    "            - Function: Conducts sound waves to the eardrum (tympanic membrane).\n",
    "            - Frequency Response: Acts as a resonance chamber, amplifying frequencies around 3 kHz, which is beneficial for speech intelligibility.\n",
    "        <img width=\"600px\" src=\"./block_3/outer_ear.jpg\">\n",
    "    - inner ear\n",
    "        - Tympanic Membrane (Eardrum):\n",
    "            - Function: Receives sound vibrations from the outer ear and transmits them to the ossicles.\n",
    "            - Frequency Response: The eardrum responds effectively to a broad range of frequencies, roughly spanning from low frequencies (20 Hz) to mid frequencies (several kHz), but is particularly sensitive around 1-3 kHz.\n",
    "        - Ossicles (Malleus, Incus, Stapes):\n",
    "            - Function: Transmit and amplify vibrations from the eardrum to the inner ear.\n",
    "            - Frequency Response: The ossicles are efficient at transmitting frequencies across the audible spectrum (20 Hz - 20 kHz) but are particularly effective in the mid-frequency range (several hundred Hz to several kHz).\n",
    "        <img width=\"600px\" src=\"./block_3/inner_ear.jpg\">\n",
    "11. What is the frequency response (roughly) of the different sub-systems(see pictures above):\n",
    "   - Pinna: Enhances frequencies around 2-5 kHz.\n",
    "   - Ear Canal: Amplifies frequencies around 3 kHz, beneficial for speech.\n",
    "   - Tympanic Membrane (Eardrum): Responds effectively across a broad frequency range, with heightened sensitivity around 1-3 kHz.\n",
    "    - Ossicles: Efficient transmission across the audible spectrum but particularly effective in the mid-frequency range (several hundred Hz to several kHz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1d6de",
   "metadata": {},
   "source": [
    "# Block IV\n",
    "1. Explain the difference between analogue and digital signals.\n",
    "    - Analog Signals:\n",
    "        - Analog signals are continuous and can vary in amplitude (strength) and frequency (waveform).\n",
    "        - They represent information by continuously varying physical quantities.\n",
    "        - Examples include sound waves, voltage levels in electrical circuits,\n",
    "        - Analog signals are susceptible to noise and interference during transmis sion and processing.\n",
    "    - Digital Signals:\n",
    "        - Digital signals are discrete and represent information using binary digits (bits) that are either 0 or 1.\n",
    "        - They are encoded using a series of discrete values or levels.\n",
    "        - Examples include digital data transmitted over computer networks, digital audio,\n",
    "        - Digital signals are less susceptible to noise and can be accurately reproduced over long distan\n",
    "<img width=\"400px\" src=\"./block_4/analog_digital.webp\">\n",
    "2. What is sampling and what is quantisation of a signal?\n",
    "    - Sampling: Involves capturing the amplitude of an analog signal at discrete time intervals to create a digital representation.\n",
    "    - Quantization: Involves mapping each sampled amplitude value to a finite set of discrete levels, determining the digital representation of the signal.\n",
    "    \n",
    "    Together, sampling and quantization allow analog signals to be accurately represented and processed in digital systems, enabling various applications such as digital audio, image processing, telecommunications, and more. The quality and fidelity of digital signals depend on the sampling rate and the number of quantization levels used during conversion.\n",
    "    \n",
    "    \n",
    "3. What is the Nyquist frequency?\n",
    "     It defines the minimum sampling rate required to accurately reconstruct a continuous-time signal from its sampled version without causing aliasing.\n",
    "\n",
    "    The Nyquist Theorem, also known as the Nyquist-Shannon sampling theorem, states that a continuous signal can be accurately represented by its samples if the sampling rate $ f_{\\text{s}} $ is at least twice the highest frequency $ f_{\\text{max}} $ present in the signal. This is expressed mathematically as:\n",
    "\n",
    "    $$ f_s \\geq 2 \\times f_{\\text{max}} $$\n",
    "\n",
    "    Where:\n",
    "    - $ f_s $ is the sampling rate (in samples per second or Hz).\n",
    "    - $ f_{\\text{max}} $ is the highest frequency component of the continuous signal.\n",
    "\n",
    "    The Nyquist frequency $ f_{\\text{Nyquist}} $, which is half of the sampling rate $ f_s $, represents the maximum frequency that can be accurately captured and represented by the sampled signal without aliasing. It is calculated as:\n",
    "\n",
    "    $$ f_{\\text{Nyquist}} = \\frac{f_s}{2} $$\n",
    "\n",
    "    When the Nyquist Theorem is satisfied, the sampled signal can be reconstructed back into the original continuous signal without loss of information or aliasing artifacts.\n",
    "    Having higher sampling rates than the Nyquist rate does not improve your signal quality. E.g.: a 200 Hz sinusoid sampled with 400 samples/sec has the same quality when it is samples with 10000 samples/sec. \n",
    "\n",
    "\n",
    "4. What is the minimum sampling frequency one should use to sample speech?\n",
    "    Given that the maximum frequency of speech $ f_{\\text{max}} $ is around 4 kHz, the minimum sampling frequency $ f_s $ required according to the Nyquist theorem would be:\n",
    "\n",
    "    $$ f_s \\geq 2 \\times f_{\\text{max}} = 2 \\times 4 \\text{ kHz} = 8 \\text{ kHz} $$\n",
    "\n",
    "    Therefore, the minimum recommended sampling frequency to accurately sample speech is \\( 8 \\text{ kHz} \\). However, higher sampling rates are often used to capture more detail and improve the quality of speech recordings and reconstructions. Commonly used sampling rates for speech applications include 16 kHz (used in telephony and low-quality voice recordings), 44.1 kHz or 48 kHz (used in digital audio for better quality), and higher rates such as 96 kHz or 192 kHz for professional audio applications.\n",
    "\n",
    "5. How many quantisation levels do you typically use to quantise a signal? \n",
    "\n",
    "    Normally 8(256 values) to 16(65536 values) bits are used\n",
    "        \n",
    "        \n",
    "6. How do you express the quantisation levels in bit? \n",
    "    \n",
    "    $ 2^b $ where $ b $ is the number of bits\n",
    "    \n",
    "    \n",
    "7. What is quantisation noise and how can it affect a signal?\n",
    "\n",
    "    <img width=\"400px\" src=\"./block_4/quantization_noise.jpg\">\n",
    "    \n",
    "9.  How many megabites of space does a 3 second stereo signal need at a sampling rate of 44100 samples/second and a 16 bit quantisation?\n",
    "    \n",
    "    44100 * 16 bit = 705600 bits = 88200 bytes\n",
    "    \n",
    "    3 * 2 * 88200 bytes = 529200 bytes = 529.2 Kbytes = 0.53 mb\n",
    "    \n",
    "    \n",
    "10. Explain what harmonic distortion is.\n",
    "\n",
    "    Harmonic distortion is a type of signal distortion that occurs when unwanted harmonics (frequencies that are integer multiples of the fundamental frequency) are added to a signal, altering its original waveform and potentially degrading its quality. This phenomenon commonly occurs in audio and electronic systems and can lead to audible artifacts or undesirable effects in sound reproduction.\n",
    "\n",
    "    Here's a breakdown of harmonic distortion:\n",
    "\n",
    "    1. **Fundamental Frequency**: In any periodic signal (such as an audio waveform), the fundamental frequency is the lowest frequency component that defines the pitch of the sound.\n",
    "\n",
    "    2. **Harmonics**: Harmonics are frequencies that are integer multiples of the fundamental frequency. For example, if the fundamental frequency is $f$, the harmonics will be $2f, 3f, 4f, \\ldots$. Harmonics contribute to the overall timbre or tone quality of a sound.\n",
    "\n",
    "    3. **Cause of Harmonic Distortion**:\n",
    "       - Harmonic distortion occurs when a system (like an amplifier or speaker) introduces new frequencies (harmonics) that were not present in the original signal.\n",
    "       - This can happen due to nonlinearities in electronic components or systems, where the output waveform does not perfectly replicate the input waveform.\n",
    "\n",
    "    4. **Types of Harmonic Distortion**:\n",
    "       - **Even Harmonics**: When the distortion introduces frequencies that are even multiples of the fundamental frequency (e.g., $2f, 4f, 6f, \\ldots$).\n",
    "       - **Odd Harmonics**: When the distortion introduces frequencies that are odd multiples of the fundamental frequency (e.g., $3f, 5f, 7f, \\ldots$).\n",
    "\n",
    "    5. **Effects of Harmonic Distortion**:\n",
    "       - Harmonic distortion can alter the sound quality, causing the signal to sound harsh, muddy, or unnatural.\n",
    "       - It can affect the clarity, detail, and dynamics of audio signals, particularly in music and speech reproduction.\n",
    "       - In extreme cases, harmonic distortion can produce audible artifacts such as buzzing, ringing, or unwanted noise.\n",
    "\n",
    "    <img width=\"400px\" src=\"./block_4/harmonic_distortion.jpg\">\n",
    "    \n",
    "    \n",
    "11. Why does harmonic distortion not occur in noise?\n",
    "    In summary, harmonic distortion does not occur in white noise because white noise lacks the periodicity and specific frequency components necessary for harmonic generation and alteration. White noise is a random, uniformly distributed signal across all frequencies, which contrasts with the predictable harmonic structure found in periodic signals susceptible to harmonic distortion.\n",
    "    \n",
    "    \n",
    "12. Explain in your own words what convolution is.\n",
    "\n",
    "    Convolution in signal processing describes how one signal (input) is transformed or processed by another signal (system response or kernel) to produce an output signal, capturing the system's influence or behavior on the input signal over time or space.\n",
    "    \n",
    "13. Convolve the number sequence 12, 3, 23, 34, 12, 13, 21 with the sequence 3, 4, 7\n",
    "    To convolve the number sequence $ x[n] = [12, 3, 23, 34, 12, 13, 21] $ with the sequence $ h[n] = [3, 4, 7] $, we can perform discrete convolution using the convolution sum formula:\n",
    "\n",
    "    $$ y[n] = \\sum_{k = -\\infty}^{\\infty} x[k] \\cdot h[n - k] $$\n",
    "\n",
    "    Let's calculate the convolution step by step:\n",
    "\n",
    "    1. **Convolution for \\( y[0] \\)**:\n",
    "       $$ y[0] = 12 \\cdot 3 = 36 $$\n",
    "\n",
    "    2. **Convolution for \\( y[1] \\)**:\n",
    "       $$ y[1] = 12 \\cdot 4 + 3 \\cdot 3 = 48 + 9 = 57 $$\n",
    "\n",
    "    3. **Convolution for \\( y[2] \\)**:\n",
    "       $$ y[2] = 12 \\cdot 7 + 3 \\cdot 4 + 23 \\cdot 3 = 84 + 12 + 69 = 165 $$\n",
    "\n",
    "    4. **Convolution for \\( y[3] \\)**:\n",
    "       $$ y[3] = 3 \\cdot 7 + 23 \\cdot 4 + 34 \\cdot 3 = 21 + 92 + 102 = 215 $$\n",
    "\n",
    "    5. **Convolution for \\( y[4] \\)**:\n",
    "       $$ y[4] = 23 \\cdot 7 + 34 \\cdot 4 + 12 \\cdot 3 = 161 + 136 + 36 = 333 $$\n",
    "\n",
    "    6. **Convolution for \\( y[5] \\)**:\n",
    "       $$ y[5] = 34 \\cdot 7 + 12 \\cdot 4 + 13 \\cdot 3 = 238 + 48 + 39 = 325 $$\n",
    "\n",
    "    7. **Convolution for \\( y[6] \\)**:\n",
    "       $$ y[6] = 12 \\cdot 7 + 13 \\cdot 4 + 21 \\cdot 3 = 84 + 52 + 63 = 199 $$\n",
    "\n",
    "    Therefore, the convolved sequence \\( y[n] \\) is given by:\n",
    "    $$ y[n] = [36, 57, 165, 215, 333, 325, 199] $$\n",
    "    \n",
    "\n",
    "14. Explain what an impulse response is and what information it contains. Why is the impulse  response so useful in signal processing?\n",
    "\n",
    "    An impulse response in signal processing describes how a system reacts to a brief input signal called an impulse. It represents the system's output when subjected to a delta function (an impulse). The impulse response contains essential information about the system's behavior, including its time-invariant properties and frequency response.\n",
    "    \n",
    "<img width=\"400px\" src=\"./block_4/impulse_response.jpg\">\n",
    "        <img width=\"400px\" src=\"./block_4/impulse_convolution.jpg\">\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fd288",
   "metadata": {},
   "source": [
    "# Block V\n",
    "<img width=\"700px\" src=\"./block_5/overview.jpg\">\n",
    "<img width=\"400px\" src=\"./block_5/pulse_train.png\">\n",
    "\n",
    "1. What is the equivalent of the 'frequency response' in the time domain?\n",
    "\n",
    "    The impulse response\n",
    "    \n",
    "    \n",
    "2. Why  does  a  pulse  contain  all  possible  frequencies  of  the  spectrum?  Give  an  intuitive  explanation starting with a pulse train.\n",
    "\n",
    "     A pulse contains all possible frequencies because its sharp transitions and finite duration lead to a wide spectrum of frequency components according to Fourier analysis. The more abrupt the transition in the pulse, the broader the spread of frequencies needed to describe it, eventually encompassing the entire spectrum. This fundamental principle underlies the relationship between time-domain signals (like pulses) and their frequency-domain representations\n",
    "    \n",
    "    \n",
    "3. Why is a single pulse so well suited to characterize a system? \n",
    "\n",
    "    When a pulse is applied as an input to a system, the system's output is described by its impulse response. The impulse response represents how the system behaves over time in response to a sudden and short-lived input.\n",
    "\n",
    "\n",
    "4. What are some possible applications of an impulse responses? \n",
    "\n",
    "    Capturing the accustic properties of a loction, like church, garage ...\n",
    "    \n",
    "    \n",
    "5. What is the time-domain equivalent to adding (multiplying) an input signal with a frequency response? \n",
    "    \n",
    "    Convolution\n",
    "    \n",
    "6. What are the similarities and differences between a pulse and white noise?\n",
    "\n",
    "    They contain all possible frequency, but a pulse is infinetally short \n",
    "       \n",
    "7. Why is it problematic to analyze speech with a single spectrum?\n",
    "        \n",
    "    It is not possible the get all details, normally a wide and narrow band spectrum is used. See picture above\n",
    "    \n",
    "8. What is a sensible way of analyzing speech with spectra? How can that lead to a spectrogram?\n",
    "\n",
    "    By stacking multiple spectra together to an spectogram?\n",
    "    \n",
    "    \n",
    "9. How can a spectrogram be created in the frequency-domain?\n",
    "\n",
    "    In summary, the spectrogram is created by applying the Short-Time Fourier Transform (STFT) to the speech signal, computing the magnitude spectra for each frame, and arranging these spectra over time and frequency to visualize the speech signal's frequency-domain representation as it evolves over time. This technique provides valuable insights into the spectral content and dynamics of speech signals.\n",
    "\n",
    "10. What is the effect of filter bandwidth on the spectro-temporal detail? \n",
    "\n",
    "     The filter bandwidth directly influences the spectro-temporal detail in a spectrogram. Narrower bandwidths provide finer frequency resolution but may sacrifice temporal resolution, while wider bandwidths enhance temporal resolution but may compromise frequency resolution. Selecting an appropriate filter bandwidth is critical for effectively capturing and interpreting spectro-temporal features in signal analysis and processing tasks.\n",
    "\n",
    "\n",
    "11. What is the relationship between filter-bandwidth and damping?\n",
    "\n",
    "    The relationship between filter bandwidth and damping is characterized by an inverse correlation: narrower bandwidths are typically associated with higher damping (steeper roll-off), while wider bandwidths tend to exhibit lower damping (gentler roll-off). This relationship plays a crucial role in filter design and optimization for various signal processing and system applications.\n",
    "    \n",
    "    \n",
    "12. Why are spectrograms so popular in Phonetics?\n",
    "\n",
    "    Spectrograms are highly valued in phonetics because they offer a comprehensive and visually intuitive representation of speech sounds, allowing researchers to investigate phonetic phenomena, acoustic properties, and linguistic variations with precision and detail. Their versatility and effectiveness make them indispensable tools in the study of speech production, perception, and communication\n",
    "    \n",
    "13. Why were spectrograms first generated with a filer-bank and later with a window-analysis in the time domain?\n",
    "\n",
    "    Because of the introduction if computer. First costly machine have been used which later have been replaes by computers which use the window-analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301e447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
